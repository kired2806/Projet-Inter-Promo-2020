{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Global_Prediction.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b941540bc9e24e60b2aabaaff775ec91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_567f1467b3e645739a3288963c2b974b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_043f025116a048be9e75e3560cf00db2","IPY_MODEL_37e408f44d0341d5bf14556063d2a939"]}},"567f1467b3e645739a3288963c2b974b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"043f025116a048be9e75e3560cf00db2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_316e5aed5cca4fa8b7619ff3c3997317","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7533,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7533,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1eafb625da484e179aaeea321d6bc41d"}},"37e408f44d0341d5bf14556063d2a939":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0e878b24ddc4e8fbd1992e2209de849","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7533/7533 [00:31&lt;00:00, 239.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25a581d787a7465a94d1cb7d9c8c965d"}},"316e5aed5cca4fa8b7619ff3c3997317":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1eafb625da484e179aaeea321d6bc41d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0e878b24ddc4e8fbd1992e2209de849":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"25a581d787a7465a94d1cb7d9c8c965d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ced1fe71eb146ac87868ea7edad89b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e6ff621bf78845298aefe8d9713e3735","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c36eaa11308e43c199a5a93e0c5af0d8","IPY_MODEL_9392b85c9b5e433e83eaf12b56921ee4"]}},"e6ff621bf78845298aefe8d9713e3735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c36eaa11308e43c199a5a93e0c5af0d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ec9605fb17547e783aacd86394ef67f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7533,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7533,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e425ded24ec4d34a53584a432c95fd4"}},"9392b85c9b5e433e83eaf12b56921ee4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a99107144594006b4753f7346133d2b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7533/7533 [1:31:26&lt;00:00,  1.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f327d8206bd455b8f23cb9588fc2f23"}},"7ec9605fb17547e783aacd86394ef67f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e425ded24ec4d34a53584a432c95fd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a99107144594006b4753f7346133d2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f327d8206bd455b8f23cb9588fc2f23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41413b30437348b4bd2b9ea890b422ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf7a36849fe449d29b8e0deafc30c51c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f9fde8ca22f943a6a4e23fabd2e99ea5","IPY_MODEL_ad827c99a4ea4885a21cfc5235a27260"]}},"bf7a36849fe449d29b8e0deafc30c51c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9fde8ca22f943a6a4e23fabd2e99ea5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_25fdc55b847f428fb24ddfb4cf168b1b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7533,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7533,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_716f3a4147f9466a9ca03b45247a5a81"}},"ad827c99a4ea4885a21cfc5235a27260":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_90b308525d54467aa773cf48ae261b2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7533/7533 [20:15&lt;00:00,  6.20it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8aeb8cf04074a34953c5a088372132a"}},"25fdc55b847f428fb24ddfb4cf168b1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"716f3a4147f9466a9ca03b45247a5a81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90b308525d54467aa773cf48ae261b2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8aeb8cf04074a34953c5a088372132a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9391a19be3d4b92983dc600bba66c68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1ba8d4eb7e0d411eaf64326bb92ad4e1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ca654f6378b0433aa06aafda336a4681","IPY_MODEL_ce8dd627806f4f508aa5ae8556d7c0f5"]}},"1ba8d4eb7e0d411eaf64326bb92ad4e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca654f6378b0433aa06aafda336a4681":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cd8d3661997b4283b21fed557fed4166","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7533,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7533,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29295c66dc3843b3a42616ac3e2a28d6"}},"ce8dd627806f4f508aa5ae8556d7c0f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c988b102e5e426babaed122ba76c1f1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7533/7533 [00:45&lt;00:00, 166.95it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a4e350963db4b66ab8bd2d063525ddf"}},"cd8d3661997b4283b21fed557fed4166":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29295c66dc3843b3a42616ac3e2a28d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c988b102e5e426babaed122ba76c1f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0a4e350963db4b66ab8bd2d063525ddf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81ee08d3694d48218638d55bb76e8503":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d8820089df70411eb788fe310bf87ec1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e2e7b6db6194e02b025d714c5034a09","IPY_MODEL_643ced3c83934a6085a1851d6bf33e2d"]}},"d8820089df70411eb788fe310bf87ec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e2e7b6db6194e02b025d714c5034a09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3098b54e46fd4234b67841a0ed4fa0ad","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7533,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7533,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b523bbc9e6b949538f6ebd38021e3e86"}},"643ced3c83934a6085a1851d6bf33e2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5a09781512d40a5a14d892308967c4b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7533/7533 [00:17&lt;00:00, 429.41it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f49d92b6d6f44d1a011438ec65900b6"}},"3098b54e46fd4234b67841a0ed4fa0ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b523bbc9e6b949538f6ebd38021e3e86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5a09781512d40a5a14d892308967c4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f49d92b6d6f44d1a011438ec65900b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71d2c11ab70a46a093e120bb59e927d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_569a5ebda0924271832e0d58b7f2df4c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_53fb6aebc0ee481bab05df82345f17f4","IPY_MODEL_cbba1542bf904e73ab288be9a2ff86e4"]}},"569a5ebda0924271832e0d58b7f2df4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53fb6aebc0ee481bab05df82345f17f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e1a3bbced104a0faab066365b43d9d9","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7533,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7533,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b491fd6ea6b410ab49eb54150097f10"}},"cbba1542bf904e73ab288be9a2ff86e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b420159549304a8f9152434fd44947d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7533/7533 [00:00&lt;00:00, 96669.32it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_173ebb345e4941068db42c8a0716f272"}},"5e1a3bbced104a0faab066365b43d9d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b491fd6ea6b410ab49eb54150097f10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b420159549304a8f9152434fd44947d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"173ebb345e4941068db42c8a0716f272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed9abd7204964f45936d7d4cc5e47056":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9113bb3ea145426fba787a32004d36ff","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7eaec8fc83343e5859ba59243d5f4b6","IPY_MODEL_ffebc3c24bf347e58a4fce44731e448a"]}},"9113bb3ea145426fba787a32004d36ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7eaec8fc83343e5859ba59243d5f4b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea041fe809a54d059615b4dc69168749","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c4cb6e187e7249d3a1083f65cbf42615"}},"ffebc3c24bf347e58a4fce44731e448a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71ec60991836435ca35c2dea6ebd2c77","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:02&lt;00:00,  1.45s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6e22cf545fe4d67a374a10def5bf818"}},"ea041fe809a54d059615b4dc69168749":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c4cb6e187e7249d3a1083f65cbf42615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71ec60991836435ca35c2dea6ebd2c77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f6e22cf545fe4d67a374a10def5bf818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z3WJ2JDgMPWU"},"source":["EN TÊTE"]},{"cell_type":"markdown","metadata":{"id":"yn2EV2S5MMM-"},"source":["Texte (description de la fonction)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97RchJsEb4oc","outputId":"6d2dccb3-d136-4623-daf0-62f6224aa322"},"source":["pip install scikit-learn-extra"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting scikit-learn-extra\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/891d2ee7bd18af8f2e1df5d63a52ee96edd0eacc21bb9627072b1c5f6a6c/scikit-learn-extra-0.1.0b2.tar.gz (615kB)\n","\u001b[K     |████████████████████████████████| 624kB 7.0MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn-extra) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn-extra) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn-extra) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->scikit-learn-extra) (1.0.0)\n","Building wheels for collected packages: scikit-learn-extra\n","  Building wheel for scikit-learn-extra (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.1.0b2-cp36-cp36m-linux_x86_64.whl size=339568 sha256=cffe840a9b652afda3f5cc7773d74cc5edcbeed6d9d24e68a3d82a7b0a31184f\n","  Stored in directory: /root/.cache/pip/wheels/04/01/0f/943bffb48bac048fa216b4325f1a6c939491ccb0ff500e08f4\n","Successfully built scikit-learn-extra\n","Installing collected packages: scikit-learn-extra\n","Successfully installed scikit-learn-extra-0.1.0b2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oy7uHDX9T0fS"},"source":["import re\r\n","import os\r\n","import nltk\r\n","import string\r\n","import numpy as np\r\n","import pandas as pd\r\n","from tqdm import tqdm_notebook\r\n","from google.colab import drive\r\n","from sklearn.manifold import TSNE\r\n","from nltk.corpus import stopwords\r\n","from nltk.corpus import stopwords\r\n","from sklearn.cluster import KMeans\r\n","from scipy.spatial import distance\r\n","from nltk.stem import WordNetLemmatizer\r\n","from sklearn.metrics import silhouette_score\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.metrics import calinski_harabasz_score\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from scipy.spatial import distance\r\n","from sklearn_extra.cluster import KMedoids"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfrHjYYu3FES","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cfbca04-18ef-482d-ccf1-b2746576dcda"},"source":["import numpy as np\r\n","import pandas as pd\r\n","import math\r\n","import re\r\n","import nltk\r\n","import pickle\r\n","import warnings\r\n","warnings.filterwarnings('ignore')\r\n","nltk.download('punkt')\r\n","\r\n","\r\n","from sklearn.decomposition import PCA\r\n","from tqdm import tqdm_notebook as tqdm\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.decomposition import PCA\r\n","from sklearn.preprocessing import StandardScaler\r\n","from nltk.tokenize import sent_tokenize, word_tokenize\r\n","\r\n","#Import Model\r\n","from sklearn.model_selection import StratifiedKFold\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.tree import DecisionTreeClassifier\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn import svm\r\n","from sklearn.linear_model import SGDClassifier\r\n","from sklearn.naive_bayes import CategoricalNB\r\n","from sklearn.preprocessing import StandardScaler\r\n","from sklearn.pipeline import make_pipeline\r\n","from sklearn.ensemble import BaggingClassifier\r\n","from sklearn.ensemble import ExtraTreesClassifier\r\n","from xgboost import XGBClassifier\r\n","from sklearn.neighbors import LocalOutlierFactor\r\n","from sklearn.ensemble import IsolationForest\r\n","\r\n","from sklearn.metrics import f1_score"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qiIIWDqN3Wik","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a9cea6c3-078d-4bd0-e3ec-8140b234e249"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qa_Dlu4cQZQW"},"source":["# Detection documents innovants et gamme de gestion"]},{"cell_type":"code","metadata":{"id":"LzG2w1ASQY2Z"},"source":["# Counts the number of words\r\n","def nb_word(text: list) -> int:\r\n","    \"\"\"Documentation\r\n","      Parameters:\r\n","        text: texts of the article\r\n","\r\n","      Out (if exists):\r\n","        nb_word: number of word in  the document\r\n","    \"\"\"\r\n","    nb_words: list = []\r\n","    nb: int = 0\r\n","    # browse through the different texts\r\n","    for i in text:\r\n","        # removes special characters\r\n","        i.replace(',', ' ')\r\n","        i.replace('.', ' ')\r\n","        i.replace('!', ' ')\r\n","        i.replace('?', ' ')\r\n","        i.replace('/', ' ')\r\n","        # creates a list with all the words present in the text\r\n","        list_words: list = i.split()\r\n","        # counts the number of words present in the text\r\n","        nb_words.append(len(list_words))\r\n","    return nb_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfvuyZoGQY0d"},"source":["# Count the number of time where the words in the list appear\r\n","def count_key_words(data: list, l: list) -> list:\r\n","    \"\"\"Documentation\r\n","    Parameters:\r\n","        data: List of articles\r\n","        l: List of word that we will check in the sentences\r\n","\r\n","    Out (if exists):\r\n","        res: List where each value is the number of time where key word appear in the article\r\n","    \"\"\"\r\n","    data = data.tolist()\r\n","    list_mot_unique=[]\r\n","    list_mot_compose=[]\r\n","    for elem in l :\r\n","      cpt = 0\r\n","      for car in elem :\r\n","        if (car == \" \") :\r\n","          cpt+=1\r\n","      if cpt==0 :\r\n","        list_mot_unique.append(elem)\r\n","      else :\r\n","        list_mot_compose.append(elem)\r\n","    res: list = []\r\n","    for i in range(len(data)):\r\n","      sentence: str = data[i]\r\n","      if sentence is None:\r\n","        res.append(0)\r\n","      else:\r\n","        sentence = sentence.lower()\r\n","        sentence = sentence.split()\r\n","        t: int = 0\r\n","        for j in sentence:\r\n","          if (j in list(list_mot_unique)):\r\n","            t = t + 1\r\n","        sentence: str = data[i]\r\n","        for elem in list_mot_compose:\r\n","          if elem in sentence:\r\n","            t = t + 1\r\n","      res.append(t)\r\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSJFMLbFQYx4"},"source":["# Count the number of sentence\r\n","def phrases(data: pd.DataFrame, col: str) -> list:\r\n","    \"\"\"Documentation\r\n","    Parameters:\r\n","        data: Dataframe with all the data\r\n","        columns: The columns of the dataframe that we will use\r\n","\r\n","    Out (if exists):\r\n","        l: List where each value is the number of sentence in a article\r\n","    \"\"\"\r\n","\r\n","    l: list = []\r\n","    for i in range(len(data[col])):\r\n","        sentences: str = data[col].tolist()[i]\r\n","\r\n","        if not isinstance(sentences, str):\r\n","            sentences: str = str(sentences)\r\n","\r\n","        if (sentences is None):\r\n","            count_sentence.append(0)\r\n","        else:\r\n","            sentences = sentences.replace(\"..\", \".\")\r\n","            sentences = sentences.replace(\"...\", \".\")\r\n","            sentences = sentences.replace(\"!\", \".\")\r\n","            sentences = sentences.replace(\"!!\", \".\")\r\n","            sentences = sentences.replace(\"!!!\", \".\")\r\n","            sentences = sentences.replace(\"?\", \".\")\r\n","            sentences = sentences.replace(\"??\", \".\")\r\n","            sentences = sentences.replace(\"???\", \".\")\r\n","            sentences = sentences.replace(\"?!\", \".\")\r\n","            sentences = sentences.replace(\"!?\", \".\")\r\n","            l.append(len(sent_tokenize(sentences)))\r\n","\r\n","    return l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmykhpejg5LK"},"source":["def count_words_diff(df: pd.DataFrame, list_key : list) -> int :\r\n","  \"\"\"Documentation\r\n","    Parameter:\r\n","        texte: text of an article\r\n","    Out:\r\n","        len(dico): lenght of a dictionary\r\n","  \"\"\"\r\n","  result = []\r\n","  for j in tqdm(range(len(df))):\r\n","    liste = df[j].split()\r\n","    dico = {}\r\n","    fait = False\r\n","    for i in range(len(liste)) :\r\n","      try : \r\n","        if (liste[i]+' '+liste[i+1]+' '+liste[i+2]) in list_key :\r\n","          dic(liste[i]+' '+liste[i+1]+' '+liste[i+2],dico)\r\n","          fait = True\r\n","        else :\r\n","          try :\r\n","            if (liste[i]+' '+liste[i+1]) in list_key :\r\n","              dic(liste[i]+' '+liste[i+1],dico)\r\n","              fait = True\r\n","          except :\r\n","            pass\r\n","      except :\r\n","        pass\r\n","      if not fait :\r\n","        dic(liste[i],dico)\r\n","      fait = False\r\n","    result.append(len(dico))\r\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cEX1RxL7g3V0"},"source":["def comparaison_words_diff(texte: str, list_key : list) -> int :\r\n","  \"\"\"Documentation\r\n","    Parameter:\r\n","        texte: text of an article\r\n","    Out:\r\n","        len(dico): lenght of a dictionary\r\n","  \"\"\"\r\n","  liste = texte.split()\r\n","  dico = {}\r\n","  fait = False\r\n","  for i in range(len(liste)) :\r\n","    try : \r\n","      if (liste[i]+' '+liste[i+1]+' '+liste[i+2]) in list_key :\r\n","        dic(liste[i]+' '+liste[i+1]+' '+liste[i+2],dico)\r\n","        fait = True\r\n","      else :\r\n","        try :\r\n","          if (liste[i]+' '+liste[i+1]) in list_key :\r\n","            dic(liste[i]+' '+liste[i+1],dico)\r\n","            fait = True\r\n","        except :\r\n","          pass\r\n","    except :\r\n","      pass\r\n","    if not fait :\r\n","      dic(liste[i],dico)\r\n","    fait = False\r\n","  return dico"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBOg_-Grg2Kg"},"source":["def count_key_words_diff(liste : list) -> int:\r\n","  \"\"\"Documentation\r\n","    Parameter:\r\n","        liste: list of key words\r\n","    Out:\r\n","        len(dico): lenght of a dictionary\r\n","  \"\"\"\r\n","  dico = {}\r\n","  for i in range(len(liste)) :\r\n","    dic(liste[i],dico)\r\n","  return (dico)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ae6kibIjgzyQ"},"source":["def dic(term: str,dico: dict) :\r\n","  \"\"\"Documentation\r\n","    Parameter:\r\n","        term: one or set of words\r\n","        dico: dictionary\r\n","  \"\"\"\r\n","  if term in dico.keys() :\r\n","    dico[term] += 1\r\n","  elif term != '' :\r\n","    dico[term] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24hiT4kEgzWu"},"source":["def key_word_in_doc(df : pd.DataFrame, list_key : list):\r\n","  key_word = []\r\n","  for i in tqdm(range(len(df))):\r\n","    sortie =  comparaison_words_diff(df[i], list_key)\r\n","    liste_cle = []\r\n","    for cle in sortie.keys():\r\n","      liste_cle.append(cle)\r\n","    tot =0\r\n","    for i in liste_cle:\r\n","      if i in (list_key.tolist()):\r\n","        tot = tot + 1\r\n","    key_word.append(tot)\r\n","  return (key_word)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lNgssJW7QYvi"},"source":["def score_to_threshold(x: int) -> int:\r\n","    \"\"\"Documentation\r\n","    Parameters:\r\n","        x: Innovation score associated with an article\r\n","    Out:\r\n","        Threshold probability used to differentiate innovative from non-innovative documents\r\n","    \"\"\"\r\n","    return np.arctan(x * 100) / np.pi * 2 * 0.2 + 0.8\r\n","\r\n","def innovation(data_nb1: pd.DataFrame, data_nb2: pd.DataFrame, data_nb3: pd.DataFrame, data_ratio1: pd.DataFrame, data_ratio2: pd.DataFrame, data_ratio3 : pd.DataFrame) -> list:\r\n","  res: list = []\r\n","  seuil: int = 0.18\r\n","  for i in tqdm(range(len(data_nb1))):\r\n","    valeur = 0.5*(data_nb1[i]*data_ratio1[i]) + 0.5*(data_nb2[i]*data_ratio2[i]) + (data_nb3[i]*data_ratio3[i])\r\n","    alea = np.random.random()\r\n","    if valeur > seuil:\r\n","        res.append(1)\r\n","    elif (valeur < seuil) & (data_nb1[i] == 0) & (data_nb2[i] == 0):\r\n","        res.append(0)\r\n","    elif (valeur < seuil) & (data_ratio1[i] < 0.0002) & (data_ratio2[i] < 0.0005):\r\n","        res.append(0)\r\n","    else:\r\n","        if valeur > seuil / 2 and alea > score_to_threshold((seuil - valeur)):\r\n","            res.append(1)\r\n","        elif valeur < seuil / 2 and alea > score_to_threshold(valeur):\r\n","            res.append(0)\r\n","        else:\r\n","            res.append('?')\r\n","  return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64i8Hhu3RkY5"},"source":["def gestion(data_nb1: pd.DataFrame, data_nb2: pd.DataFrame, data_nb3: pd.DataFrame, data_ratio1: pd.DataFrame, data_ratio2: pd.DataFrame, data_ratio3 : pd.DataFrame) -> list:\r\n","  res: list = []\r\n","  seuil: int = 0.70\r\n","  for i in tqdm(range(len(data_nb1))):\r\n","    valeur = 0.5*(data_nb1[i]*data_ratio1[i]) + 0.5*(data_nb2[i]*data_ratio2[i]) + (data_nb3[i]*data_ratio3[i])\r\n","    alea = np.random.random()\r\n","    if valeur > seuil:\r\n","        res.append(1)\r\n","    elif (valeur < seuil) & (data_nb1[i] == 0) & (data_nb2[i] == 0):\r\n","        res.append(0)\r\n","    elif (valeur < seuil) & (data_ratio1[i] < 0.0002) & (data_ratio2[i] < 0.0005):\r\n","        res.append(0)\r\n","    else:\r\n","        if valeur > seuil / 2 and alea > score_to_threshold((seuil - valeur)):\r\n","            res.append(1)\r\n","        elif valeur < seuil / 2 and alea > score_to_threshold(valeur):\r\n","            res.append(0)\r\n","        else:\r\n","            res.append('?')\r\n","  return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5TZ4u31RkUj"},"source":["def create_features(df : pd.DataFrame, texte : str, title : str, inno_ges : str, df_lexique : pd.DataFrame):\r\n","\r\n","  df[\"nb_key_words\"]: pd.DataFrame = count_key_words(df[texte], df_lexique[\"key_words_lemma\"])\r\n","  df[\"nb_key_words_title\"]: pd.DataFrame = count_key_words(df[title], df_lexique[\"key_words_lemma\"])\r\n","  df[\"nb_words\"]: pd.DataFrame = nb_word(df[texte])\r\n","  df[\"nb_words_title\"]: pd.DataFrame = nb_word(df[title])\r\n","  df[\"nb_sentences\"]: pd.DataFrame  = phrases(df, texte)\r\n","  df[\"average_word_sentence\"]: pd.DataFrame = df[\"nb_words\"] / df[\"nb_sentences\"]\r\n","  df[\"ratio_word_title_on_word\"]: pd.DataFrame  = df[\"nb_words_title\"] / df[\"nb_words\"]\r\n","  df['ratio_key_words']: pd.DataFrame  = df['nb_key_words']/df['nb_words']\r\n","  df['ratio_key_words']: pd.DataFrame  = df['ratio_key_words'].fillna(0)\r\n","  df['ratio_key_sentences']: pd.DataFrame  = df['nb_key_words']/df['nb_sentences']\r\n","  df['ratio_key_sentences']: pd.DataFrame  = df['ratio_key_sentences'].fillna(0)\r\n","  df['ratio_key_word_title']: pd.DataFrame  = df['nb_key_words_title'] / df['nb_words_title']\r\n","  df['ratio_key_word_title']: pd.DataFrame  = df['ratio_key_word_title'].fillna(0)\r\n","  df['word_key_diff']: pd.DataFrame = key_word_in_doc(df[texte].tolist(), df_lexique['key_words_lemma'])\r\n","  df['word_diff']: pd.DataFrame = count_words_diff(df[texte].tolist(), df_lexique['key_words_lemma'])\r\n","  df['ratio_key_word_diff']: pd.DataFrame  = df['word_key_diff'] / df['word_diff']\r\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILJXday4RkSN"},"source":["def create_label(df : pd.DataFrame, inno_ges : str, df_lexique : pd.DataFrame):\r\n","  df = create_features(df, \"art_content_clean_without_lem\", \"art_title\", inno_ges, df_lexique)\r\n","\r\n","  if (inno_ges == 'innovation'):\r\n","    df['prediction_supervise'] = innovation(df['nb_key_words'].tolist(),df['nb_key_words_title'].tolist(),df['word_key_diff'].tolist(), df['ratio_key_words'].tolist(),df['ratio_key_word_title'].tolist(), df['ratio_key_word_diff'].tolist())\r\n","  elif (inno_ges == 'gestion'):\r\n","    df['prediction_supervise'] = gestion(df['nb_key_words'].tolist(),df['nb_key_words_title'].tolist(),df['word_key_diff'].tolist(), df['ratio_key_words'].tolist(),df['ratio_key_word_title'].tolist(), df['ratio_key_word_diff'].tolist())\r\n","\r\n","  var_utile = df.drop([\"art_id\",\"art_content_clean_without_lem\",\"art_title\",\"prediction_supervise\"], axis = 1)\r\n","  var_utile = var_utile.drop([\"nb_key_words\",\"nb_key_words_title\",\"nb_words\",\"nb_words_title\",\"nb_sentences\",\"average_word_sentence\",\"ratio_word_title_on_word\",'ratio_key_words','ratio_key_sentences','ratio_key_word_title','word_key_diff','word_diff','ratio_key_word_diff'],axis = 1)\r\n","\r\n","  var_utile = pd.concat([var_utile, df['prediction_supervise']], axis = 1)\r\n","\r\n","  tout = var_utile[var_utile['prediction_supervise'] != '?']\r\n","  unlabeled = var_utile[var_utile['prediction_supervise'] == '?']\r\n","\r\n","  X_train = tout.drop('prediction_supervise', axis=1)\r\n","  y_train = tout.prediction_supervise\r\n","  y_train = pd.to_numeric(y_train)\r\n","\r\n","  X_unlabeled = unlabeled.drop('prediction_supervise', axis=1)\r\n","\r\n","  if (inno_ges == 'innovation'):\r\n","    model1 = XGBClassifier()\r\n","    model2 = DecisionTreeClassifier(random_state=0)\r\n","    model3 = LogisticRegression(penalty = 'l1', solver = 'liblinear')\r\n","  elif (inno_ges == 'gestion'):\r\n","    model1 = XGBClassifier()\r\n","    model2 = LogisticRegression(penalty = 'l1', solver = 'liblinear')\r\n","    model3 = svm.SVC(C = 4,kernel='linear', probability= True)\r\n","  # Initiate iteration counter\r\n","  iterations = 0\r\n","\r\n","  # Containers to hold f1_scores and # of pseudo-labels\r\n","  train_f1s = []\r\n","  pseudo_labels = []\r\n","\r\n","  # Assign value to initiate while loop\r\n","  high_prob = [1] \r\n","\r\n","  # Loop will run until there are no more high-probability pseudo-labels\r\n","  while len(high_prob) > 0:\r\n","        \r\n","    # Fit classifier and make train/test predictions\r\n","    model1.fit(X_train, y_train)\r\n","    y_hat_train = model1.predict(X_train)\r\n","\r\n","    # Calculate and print iteration # and f1 scores, and store f1 scores\r\n","    train_f1 = f1_score(y_train, y_hat_train)\r\n","    print(f\"Iteration {iterations}\")\r\n","    print(f\"Train f1: {train_f1}\")\r\n","    train_f1s.append(train_f1)\r\n","   \r\n","    if (len(X_unlabeled) > 0):\r\n","      # Generate predictions and probabilities for unlabeled data\r\n","      print(f\"Now predicting labels for unlabeled data...\")\r\n","\r\n","      pred_probs : np.ndarray = model1.predict_proba(X_unlabeled)\r\n","      preds : np.ndarray = model1.predict(X_unlabeled)\r\n","      prob_0 : list = pred_probs[:,0]\r\n","      prob_1 : list = pred_probs[:,1]\r\n","\r\n","      # Store predictions and probabilities in dataframe\r\n","      df_pred_prob : pd.DataFrame = pd.DataFrame([])\r\n","      df_pred_prob['preds'] = preds\r\n","      df_pred_prob['prob_0'] = prob_0\r\n","      df_pred_prob['prob_1'] = prob_1\r\n","      df_pred_prob.index = X_unlabeled.index\r\n","    \r\n","      # Separate predictions with > 99% probability\r\n","      high_prob : pd.DataFrame = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > 0.99],\r\n","                           df_pred_prob.loc[df_pred_prob['prob_1'] > 0.99]],\r\n","                          axis=0)\r\n","      print(f\"{len(high_prob)} high-probability predictions added to training data.\")\r\n","    \r\n","      pseudo_labels.append(len(high_prob))\r\n","\r\n","      # Add pseudo-labeled data to training data\r\n","      X_train = pd.concat([X_train, X_unlabeled.loc[high_prob.index]], axis=0)\r\n","      y_train = pd.concat([y_train, high_prob.preds])      \r\n","    \r\n","      # Drop pseudo-labeled instances from unlabeled data\r\n","      X_unlabeled = X_unlabeled.drop(index=high_prob.index)\r\n","      print(f\"{len(X_unlabeled)} unlabeled instances remaining.\\n\")\r\n","    \r\n","      # Update iteration counter\r\n","      iterations += 1\r\n","    else :\r\n","      high_prob = []\r\n","      print(f'end of process.')\r\n","\r\n","  # Initiate iteration counter\r\n","  iterations = 0\r\n","\r\n","  # Containers to hold f1_scores and # of pseudo-labels\r\n","  train_f1s = []\r\n","  pseudo_labels = []\r\n","\r\n","  # Assign value to initiate while loop\r\n","  high_prob = [1] \r\n","\r\n","  # Loop will run until there are no more high-probability pseudo-labels\r\n","  while len(high_prob) > 0:\r\n","        \r\n","    # Fit classifier and make train/test predictions\r\n","    model2.fit(X_train, y_train)\r\n","    y_hat_train = model2.predict(X_train)\r\n","\r\n","    # Calculate and print iteration # and f1 scores, and store f1 scores\r\n","    train_f1 = f1_score(y_train, y_hat_train)\r\n","    print(f\"Iteration {iterations}\")\r\n","    print(f\"Train f1: {train_f1}\")\r\n","    train_f1s.append(train_f1)\r\n","   \r\n","    if (len(X_unlabeled) > 0):\r\n","      # Generate predictions and probabilities for unlabeled data\r\n","      print(f\"Now predicting labels for unlabeled data...\")\r\n","\r\n","      pred_probs : np.ndarray = model2.predict_proba(X_unlabeled)\r\n","      preds : np.ndarray = model2.predict(X_unlabeled)\r\n","      prob_0 : list = pred_probs[:,0]\r\n","      prob_1 : list = pred_probs[:,1]\r\n","\r\n","      # Store predictions and probabilities in dataframe\r\n","      df_pred_prob : pd.DataFrame = pd.DataFrame([])\r\n","      df_pred_prob['preds'] = preds\r\n","      df_pred_prob['prob_0'] = prob_0\r\n","      df_pred_prob['prob_1'] = prob_1\r\n","      df_pred_prob.index = X_unlabeled.index\r\n","    \r\n","      # Separate predictions with > 99% probability\r\n","      high_prob : pd.DataFrame = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > 0.99],\r\n","                           df_pred_prob.loc[df_pred_prob['prob_1'] > 0.99]],\r\n","                          axis=0)\r\n","      print(f\"{len(high_prob)} high-probability predictions added to training data.\")\r\n","    \r\n","      pseudo_labels.append(len(high_prob))\r\n","\r\n","      # Add pseudo-labeled data to training data\r\n","      X_train = pd.concat([X_train, X_unlabeled.loc[high_prob.index]], axis=0)\r\n","      y_train = pd.concat([y_train, high_prob.preds])      \r\n","    \r\n","      # Drop pseudo-labeled instances from unlabeled data\r\n","      X_unlabeled = X_unlabeled.drop(index=high_prob.index)\r\n","      print(f\"{len(X_unlabeled)} unlabeled instances remaining.\\n\")\r\n","    \r\n","      # Update iteration counter\r\n","      iterations += 1\r\n","    else :\r\n","      high_prob = []\r\n","      print(f'end of process.')\r\n","\r\n","  # Initiate iteration counter\r\n","  iterations = 0\r\n","\r\n","  # Containers to hold f1_scores and # of pseudo-labels\r\n","  train_f1s = []\r\n","  pseudo_labels = []\r\n","\r\n","  # Assign value to initiate while loop\r\n","  high_prob = [1] \r\n","\r\n","  # Loop will run until there are no more high-probability pseudo-labels\r\n","  while len(high_prob) > 0:\r\n","        \r\n","    # Fit classifier and make train/test predictions\r\n","    model3.fit(X_train, y_train)\r\n","    y_hat_train = model3.predict(X_train)\r\n","\r\n","    # Calculate and print iteration # and f1 scores, and store f1 scores\r\n","    train_f1 = f1_score(y_train, y_hat_train)\r\n","    print(f\"Iteration {iterations}\")\r\n","    print(f\"Train f1: {train_f1}\")\r\n","    train_f1s.append(train_f1)\r\n","   \r\n","    if (len(X_unlabeled) > 0):\r\n","      # Generate predictions and probabilities for unlabeled data\r\n","      print(f\"Now predicting labels for unlabeled data...\")\r\n","\r\n","      pred_probs : np.ndarray = model3.predict_proba(X_unlabeled)\r\n","      preds : np.ndarray = model3.predict(X_unlabeled)\r\n","      prob_0 : list = pred_probs[:,0]\r\n","      prob_1 : list = pred_probs[:,1]\r\n","\r\n","      # Store predictions and probabilities in dataframe\r\n","      df_pred_prob : pd.DataFrame = pd.DataFrame([])\r\n","      df_pred_prob['preds'] = preds\r\n","      df_pred_prob['prob_0'] = prob_0\r\n","      df_pred_prob['prob_1'] = prob_1\r\n","      df_pred_prob.index = X_unlabeled.index\r\n","    \r\n","      # Separate predictions with > 60% probability\r\n","      high_prob : pd.DataFrame = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > 0.60],\r\n","                           df_pred_prob.loc[df_pred_prob['prob_1'] > 0.60]],\r\n","                          axis=0)\r\n","      print(f\"{len(high_prob)} high-probability predictions added to training data.\")\r\n","    \r\n","      pseudo_labels.append(len(high_prob))\r\n","\r\n","      # Add pseudo-labeled data to training data\r\n","      X_train = pd.concat([X_train, X_unlabeled.loc[high_prob.index]], axis=0)\r\n","      y_train = pd.concat([y_train, high_prob.preds])      \r\n","    \r\n","      # Drop pseudo-labeled instances from unlabeled data\r\n","      X_unlabeled = X_unlabeled.drop(index=high_prob.index)\r\n","      print(f\"{len(X_unlabeled)} unlabeled instances remaining.\\n\")\r\n","    \r\n","      # Update iteration counter\r\n","      iterations += 1\r\n","    else :\r\n","      high_prob = []\r\n","      print(f'end of process.')\r\n","\r\n","  X_train['prediction_supervise'] = y_train\r\n","  X_train['index'] = X_train.index\r\n","  df[\"index\"] = df.index\r\n","  df_final = pd.merge(left=df, right=X_train, left_on='index', right_on='index')\r\n","  df_final = df_final[['art_id','prediction_supervise_y']]\r\n","  df_final = df_final.rename(columns = {'prediction_supervise_y': 'prediction_supervise'})\r\n","  return df_final"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyanKb0LoTIi"},"source":["def compute_score(data):\r\n","  '''Documentation\r\n","  Parameters :\r\n","    data : Data used to compute the score of innovation and the score of gamme gestion\r\n","  Output :\r\n","    data : DataFrame which contain the id, the score of innovation and the score of gamme gestion\r\n","  '''\r\n","  data.reset_index(drop=True,inplace = True)\r\n","  #Creation of the kfold for split train and test\r\n","  skf = StratifiedKFold(n_splits=5, random_state = 42, shuffle=True)\r\n","  data[\"score_innovant\"] = 0\r\n","  data[\"score_gamme_gestion\"] = 0\r\n","  #We create cross validation to predict the proba on test set (and use this proba as score)\r\n","  for train_index, test_index in skf.split(data, data[\"innovant\"]):\r\n","    #Initialisation of the model\r\n","    model = RandomForestClassifier(random_state=42)\r\n","    #We train on train set\r\n","    model.fit(data.drop([\"innovant\",\"gamme_gestion\",\"art_id\",\"score_innovant\",\"score_gamme_gestion\"],axis = 1).loc[train_index],data.loc[train_index,\"innovant\"])\r\n","    #We predict on test set and we use the proba make the decision score\r\n","    data.loc[test_index,\"score_innovant\"] = model.predict_proba(data.drop([\"innovant\",\"gamme_gestion\",\"art_id\",\"score_innovant\",\"score_gamme_gestion\"],axis = 1).loc[test_index])[:,1]\r\n","  #We create cross validation to predict the proba on test set (and use this proba as score)\r\n","  for train_index, test_index in skf.split(data, data[\"innovant\"]):\r\n","    #Initialisation of the model\r\n","    model = RandomForestClassifier(random_state=42)\r\n","    #We train on train set\r\n","    model.fit(data.drop([\"innovant\",\"gamme_gestion\",\"art_id\",\"score_innovant\",\"score_gamme_gestion\"],axis = 1).loc[train_index],data.loc[train_index,\"gamme_gestion\"])\r\n","    #We predict on test set and we use the proba make the decision score\r\n","    data.loc[test_index,\"score_gamme_gestion\"] = model.predict_proba(data.drop([\"innovant\",\"gamme_gestion\",\"art_id\",\"score_innovant\",\"score_gamme_gestion\"],axis = 1).loc[test_index])[:,1]\r\n","  #We round the score of innovation and gamme gestion\r\n","  data[\"score_innovant\"] = np.round(data[\"score_innovant\"],3)\r\n","  data[\"score_gamme_gestion\"] = np.round(data[\"score_gamme_gestion\"],3)\r\n","  return data[[\"art_id\",\"score_innovant\",\"score_gamme_gestion\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BOEdbN5CuNyT"},"source":["def train_model(data,path_to):\r\n","  '''Documentation\r\n","  Parameters:\r\n","        data : data to train the model\r\n","        data_path : path to save data\r\n","  '''\r\n","  #Initialisation of the model\r\n","  model = RandomForestClassifier(random_state=42)\r\n","  #Train model\r\n","  model.fit(data.drop([\"innovant\",\"gamme_gestion\"], axis = 1),data[\"innovant\"])\r\n","  #Save the model\r\n","  pickle.dump(model, open(path_to + \"model_innovant.pkl\", 'wb'))\r\n","\r\n","  #Initialisation of the model\r\n","  model = RandomForestClassifier(random_state=42)\r\n","  #Train model\r\n","  model.fit(data.drop([\"innovant\",\"gamme_gestion\"], axis = 1),data[\"gamme_gestion\"])\r\n","  #Save the model\r\n","  pickle.dump(model, open(path_to + \"model_gamme_gestion.pkl\", 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"evrqzi4X3Xks"},"source":["# Detection New Documents"]},{"cell_type":"code","metadata":{"id":"SGKRD1Lp3W4b"},"source":["def duplicate_prediction(data: pd.DataFrame,path_save: str) -> np.ndarray:\r\n","    \"\"\"Documentation\r\n","    Parameters:\r\n","        data_path : path to data\r\n","    Out:\r\n","        prediction : list of prediction (-1 : News, 1: Common)\r\n","    \"\"\"\r\n","\r\n","    dataout = pd.DataFrame(data[\"art_id\"].values,columns = [\"art_id\"])\r\n","    data = data.drop([\"art_id\"],axis = 1)\r\n","\r\n","    sc: StandardScaler = StandardScaler()\r\n","    X: np.ndarray = sc.fit_transform(data)\r\n","    pickle.dump(sc, open(path_save + \"scaler.pkl\", 'wb'))\r\n","\r\n","    tsne: TSNE = TSNE(n_components=3)\r\n","    X: np.ndarray = tsne.fit_transform(X)\r\n","    pickle.dump(sc, open(path_save + \"tsne.pkl\", 'wb'))\r\n","    \r\n","    clf: IsolationForest = IsolationForest(random_state=0, contamination=0.01)\r\n","    dataout[\"prediction_nouveau\"]: np.ndarray = clf.fit_predict(X)\r\n","    dataout[\"score_nouveau\"]: np.ndarray = clf.decision_function(X)\r\n","    pickle.dump(sc, open(path_save + \"model_novelty.pkl\", 'wb'))\r\n","\r\n","    return dataout"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GMBKujOiQ8Sy"},"source":["# Détection de clusters"]},{"cell_type":"code","metadata":{"id":"07HA6wNCQ8Co"},"source":["#Find the optimal number of clusters, k\r\n","def optimal_cluster(X: pd.DataFrame)->int:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      X: dataset containint all our datas we want to train the model with\r\n","  Output:\r\n","      (list_k[np.argmax(list_error_silhouette)]): optimal value of clusters, k\r\n","  \"\"\"\r\n","  list_error_silhouette:list = []\r\n","  list_k:list = []\r\n","  K:range = range(9,26)\r\n","  sc: StandardScaler = StandardScaler()\r\n","  X: np.ndarray = sc.fit_transform(X)\r\n","  #create the range of k which are going to be used in our loop\r\n","  for k in tqdm_notebook(K):\r\n","    pca: PCA = PCA(n_components=10,random_state = 1)\r\n","    km = KMedoids(n_clusters=k,metric='cosine',  random_state=0)\r\n","    y = km.fit_predict(pca.fit_transform(X))\r\n","    list_k.append(k)\r\n","    #create a list with all k values\r\n","    list_error_silhouette.append(silhouette_score(X,y))\r\n","    #return the maximum of the error based on the silhouette corresponding to the optimal value of k\r\n","  return (list_k[np.argmax(list_error_silhouette)])\r\n","\r\n","#Train the chosen model on X matrix with the chosen number of clusters (nb_cluster) and return the trained model for later use\r\n","def training(X: pd.DataFrame, nb_cluster: int, path_save: str)->(KMedoids, PCA, StandardScaler):\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      X: The data to predict\r\n","      nb_cluster : The number of cluster\r\n","      path_save : The path to save the model\r\n","  Output:\r\n","      km : The model\r\n","      pca : The pca\r\n","      sc : The normalisation\r\n","  \"\"\"\r\n","  #Nomalisation\r\n","  sc: StandardScaler = StandardScaler()\r\n","  X: np.ndarray = sc.fit_transform(X)\r\n","  pickle.dump(sc, open(path_save + \"scaler_cluster.pkl\", 'wb'))\r\n","  #PCA\r\n","  pca: PCA = PCA(n_components=10,random_state = 1)\r\n","  X: np.ndarray = pca.fit_transform(X)\r\n","  pickle.dump(sc, open(path_save + \"pca_cluster.pkl\", 'wb'))\r\n","  #Kmenoids\r\n","  km: KMedoids = KMedoids(n_clusters=nb_cluster,metric='cosine',  random_state=0).fit(X)\r\n","  pickle.dump(sc, open(path_save + \"model_cluster.pkl\", 'wb'))\r\n","  return km, pca, sc\r\n","\r\n","def predict(X: pd.DataFrame,model: KMedoids,pca: PCA,sc: StandardScaler)->list:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      X: The data to predict\r\n","      km: The model\r\n","      pca: The pca to make before to run the model\r\n","      sc: The normalisation to make before to run the pca\r\n","  Output:\r\n","      return prediction\r\n","  \"\"\"\r\n","  #Normalisation\r\n","  X: np.ndarray = sc.transform(X)\r\n","  #pca\r\n","  X: np.ndarray = pca.transform(X)\r\n","  #prediction\r\n","  return model.predict(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsJfPoQeQ8Aq"},"source":["#calculate the chosen distance (euclidean or cosine) between the values inside\r\n","#the cluster with label denomination and the centroid of this cluster.\r\n","def compute_distance(v: np.ndarray,km: KMedoids,label: int,pca: PCA,sc: StandardScaler)->list:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      v: The article to compute\r\n","      km: The model\r\n","      label: The number of the cluster\r\n","      pca: The pca to make before to run the model\r\n","      sc: The normalisation to make before to run the pca\r\n","  Output:\r\n","      distance bewteen the point and the center of the cluster\r\n","  \"\"\"\r\n","  #We make the euclidian distance between the point and the center of the cluster\r\n","  return distance.euclidean(pca.transform(sc.transform(v.reshape(1, -1))),km.cluster_centers_[label])\r\n","\r\n","def obtain_word(list_content: list, type = \"idf\")-> str:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      X: contains the data\r\n","  Output:\r\n","      (list_k[np.argmax(list_error_silhouette)]): optimal value of clusters, k\r\n","  \"\"\"\r\n","  if type == \"idf\":\r\n","    #We drop english word because there is some english word in the content\r\n","    vectorizer = TfidfVectorizer(stop_words = \"english\")\r\n","    X = vectorizer.fit_transform(list_content)\r\n","    #Vectorizes all the tags in the train set while cleaning it from stop words\r\n","  elif type == \"bow\":\r\n","    #We drop english word because there is some english word in the content\r\n","    vectorizer = CountVectorizer(stop_words = \"english\")\r\n","    X = vectorizer.fit_transform(list_content)\r\n","    #Vectorizes all the tags in the train set while cleaning it from stop words\r\n","  else:\r\n","    print(\"None\")\r\n","    #return an error while the type specified is not idf or bow\r\n","  #We create a dataframe with the sum of the bow/td-idf and we take the 3 word with the biggest score\r\n","  temp_data = pd.DataFrame(np.array(np.sum(X,axis = 0))[0], columns = [\"score\"])\r\n","  temp_data[\"word\"] = vectorizer.get_feature_names()\r\n","  #Create a word column from feature integer indices to feature name.\r\n","  temp_data = temp_data.sort_values(by = [\"score\"], ascending = False)\r\n","  return temp_data.iloc[0,1] + \"/\" + temp_data.iloc[1,1] + \"/\" + temp_data.iloc[2,1]\r\n","\r\n","#Get the contnt of an article except the words present in the whitelist\r\n","def whitelist_content(list_content: list, list_whitelist: list) -> np.ndarray:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      list_content: A list of articles\r\n","      list_whitelist: A whitelist of word\r\n","  Output:\r\n","      final_content: A list of articles without the word in the whitelist\r\n","  \"\"\"\r\n","  #We create a list\r\n","  final_content = []\r\n","  for content in list_content:\r\n","    #We take every word witch are not present in whitelist\r\n","    temp_content = [w for w in content.split() if not w in list_whitelist]\r\n","    #We join all the word to create a sentence\r\n","    temp_content = \" \".join(temp_content)\r\n","    final_content.append(temp_content)\r\n","  return np.array(final_content)\r\n","\r\n","#EN ENTREE EMBEDDING + PREDICTION + ART_ID + art_content_clean_without_lem (contenu du texte lematizer)\r\n","def get_label_title(data: pd.DataFrame,whitelist: list,km: KMedoids,pca: PCA,sc: StandardScaler) -> dict:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      data: A dataframe containing all our datas we want to work with\r\n","      whitelist: a whitelist of words we want to avoid in labels title\r\n","  Output:\r\n","      themes: A string containing our title of the chosen label\r\n","  \"\"\"\r\n","  #We create the dictionnary that will contain the label corresponding to each cluster\r\n","  themes = {}\r\n","  for label in np.unique(data[\"prediction\"]):\r\n","    #We create a copy of the dataframe which only contain the cluster corresponding to the value of label\r\n","    sub_data = data.query(\"prediction == @label\").drop([\"prediction\"],axis = 1).copy()\r\n","    #We compute the distance bewteen the center of the cluster and all the point of the cluster\r\n","    sub_data[\"score\"] = sub_data.drop([\"art_id\",\"art_content_clean_without_lem\"], axis = 1).apply(compute_distance,axis = 1,raw = True, args = (km,0,pca,sc))\r\n","    #We take the five closest document of the center\r\n","    head_content = sub_data.sort_values(by = [\"score\"], ascending = True).head(5)[\"art_content_clean_without_lem\"].values\r\n","    #We drop the word in the whitelist\r\n","    head_content = whitelist_content(head_content,whitelist)\r\n","    #We get the label of ech cluster by checking the three recurents words\r\n","    themes[label] = obtain_word(head_content, type = \"bow\")\r\n","  return themes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCh5C7-7Q7-U"},"source":["# Clusters the dataset with the optimal number of clusters and return\r\n","def predict_cluster(data: pd.DataFrame, path_save: str)-> pd.DataFrame:\r\n","  \"\"\"Documentation\r\n","  Parameters:\r\n","      data: A dataframe containing all our datas we want to work with\r\n","  Output:\r\n","      data[[\"art_id\",\"prediction\"]]: A dataframe containing our id and the title of the chosen label\r\n","      model: the model trained with the optimal number of clusters\r\n","  \"\"\"\r\n","  #We use the function higher to obtain the good number of clusters\r\n","  nb_cluster = optimal_cluster(data.drop([\"art_id\",\"art_content_clean_without_lem\"], axis = 1))\r\n","  print(\"We take \" + str(nb_cluster) + \" clusters.\")\r\n","  #We train the kmenoide, pca and normalisation to make prediction\r\n","  model, pca, sc = training(data.drop([\"art_id\",\"art_content_clean_without_lem\"], axis = 1),nb_cluster, path_save)\r\n","  #We predict the cluster with the kmenoide, pca and normalisation trained\r\n","  data[\"prediction\"] = predict(data.drop([\"art_id\",\"art_content_clean_without_lem\"], axis = 1),model, pca, sc)\r\n","  #We create a whitelist to drop some recurents word that was not drop\r\n","  whitelist = [\"plus\",\"tout\",\"cette\",\"ca\",\"etre\",\"dire\",\"faut\",\"fait\",\"faire\",\"donc\"]\r\n","  #We create the label of each cluster\r\n","  data[\"name_theme\"] = data[\"prediction\"].map(get_label_title(data,whitelist,model,pca,sc))\r\n","  return data[[\"art_id\",\"name_theme\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cP1b7BclQ4zP"},"source":["#Compilation grosse fonction"]},{"cell_type":"code","metadata":{"id":"rCBJeeIi4K4L"},"source":["def all_prediction(data: pd.DataFrame,lexique_innovant: pd.DataFrame,lexique_gestion: pd.DataFrame,path_save: str) -> pd.DataFrame:\r\n","  '''Documentation\r\n","  Parameters:\r\n","      data: A dataframe containing 3 columns(art_id, art_content, art_uitle) and the bow\r\n","  Output:\r\n","      data : A dataframe with all the the predicted features\r\n","  '''\r\n","  #We compute innovant and gamme gestion\r\n","  print(\"Phase 1\")\r\n","  #We predict the label innovant\r\n","  data_temp_innovant = create_label(data.copy(),\"innovation\",lexique_innovant)\r\n","  data_temp_innovant.columns = [\"art_id\",\"innovant\"]\r\n","  #We predict the label gestion\r\n","  data_temp_gestion = create_label(data.copy(),\"gestion\",lexique_gestion)\r\n","  data_temp_gestion.columns = [\"art_id\",\"gamme_gestion\"]\r\n","  #We make a concatenation bewteen the input data and the predicted label\r\n","  data = data.merge(data_temp_innovant, on = \"art_id\").merge(data_temp_gestion, on = \"art_id\")\r\n","  data.rename(columns = {\"innovant_y\" : \"innovant\",\"gamme_gestion_y\" : \"gamme_gestion\"}, inplace = True)\r\n","\r\n","  #We compute the score\r\n","  print(\"Phase 2\")\r\n","  #We predict the score of innovant and gamme gestion\r\n","  data_temp = compute_score(data.drop([\"art_content_clean_without_lem\",\"art_title\"], axis = 1).copy())\r\n","  data = data.merge(data_temp, on = \"art_id\")\r\n","  #We make a concatenation bewteen the input data and the predicted label\r\n","  data.rename(columns = {\"score_innovant_y\" : \"score_innovant\",\"score_gamme_gestion_y\" : \"score_gamme_gestion\"}, inplace = True)\r\n","  #We train model\r\n","  train_model(data.drop([\"art_id\",\"art_content_clean_without_lem\",\"score_innovant\",\"score_gamme_gestion\",\"art_title\"], axis = 1).copy(),path_save)\r\n","\r\n","  #We compute the new documents\r\n","  print(\"Phase 3\")\r\n","  #We predict the new document\r\n","  data_temp = duplicate_prediction(data.query(\"innovant == 1\").query(\"gamme_gestion == 1\").drop([\"art_content_clean_without_lem\",\"art_title\",\"score_innovant\",\"score_gamme_gestion\",\"innovant\",\"gamme_gestion\"], axis = 1).copy(),path_save)\r\n","  #We make a concatenation bewteen the input data and the predicted label\r\n","  data_temp[\"prediction_nouveau\"] = data_temp[\"prediction_nouveau\"].replace([1,-1],[0,1])\r\n","  data = data.merge(data_temp,how = \"left\", on = \"art_id\")\r\n","  data.rename(columns = {\"score_nouveau\" : \"score_nouveau\"}, inplace = True)\r\n","\r\n","  #On regarde les clusters\r\n","  print(\"Phase 4\")\r\n","  data_temp = predict_cluster(data.query(\"innovant == 1\").query(\"gamme_gestion == 1\").drop([\"innovation\",\"gamme_gestion\",\"score_innovant\",\"score_gamme_gestion\",\"prediction_nouveau\",\"score_nouveau\",\"art_title\"], axis = 1).copy(),path_save)\r\n","  data = data.merge(data_temp,how = \"left\", on = \"art_id\")\r\n","  data = data[[\"art_id\",\"innovant\",\"gamme_gestion\",\"score_innovant\",\"score_gamme_gestion\",\"prediction_nouveau\",\"score_nouveau\",\"name_theme\"]].copy()\r\n","  data.rename(columns = {\"name_theme\" : \"theme\",\"prediction_nouveau\" : \"nouveau\"}, inplace = True)\r\n","  \r\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yanczv0AR16w"},"source":["# We run the function"]},{"cell_type":"code","metadata":{"id":"rzH5Tw0t4Wgb"},"source":["data = pd.read_json(\r\n","    \"/content/drive/MyDrive/G5 Inter-Promo 2021/Données/Input/g3_BOW_v1.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fgqky6Z2Qjgw"},"source":["data_title = pd.read_csv(\r\n","    '/content/drive/MyDrive/G5 Inter-Promo 2021/Données/Input/Data_With_Features_Syntax.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONlQnNgTqKNs"},"source":["df_lexique_innovation: pd.DataFrame = pd.read_json(\r\n","    \"/content/drive/MyDrive/G5 Inter-Promo 2021/Données/Output/Innovation/df_lexique_lemma.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbpQQY9jQjoE"},"source":["df_lexique_gestion: pd.DataFrame = pd.read_json(\r\n","    \"/content/drive/MyDrive/G5 Inter-Promo 2021/Données/Output/Innovation/df_lexique_gammes_gestion.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38LSzfwPXrP2"},"source":["data[\"art_title\"] = data_title.loc[data.index,\"art_title\"]\r\n","del(data_title)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b941540bc9e24e60b2aabaaff775ec91","567f1467b3e645739a3288963c2b974b","043f025116a048be9e75e3560cf00db2","37e408f44d0341d5bf14556063d2a939","316e5aed5cca4fa8b7619ff3c3997317","1eafb625da484e179aaeea321d6bc41d","b0e878b24ddc4e8fbd1992e2209de849","25a581d787a7465a94d1cb7d9c8c965d","0ced1fe71eb146ac87868ea7edad89b5","e6ff621bf78845298aefe8d9713e3735","c36eaa11308e43c199a5a93e0c5af0d8","9392b85c9b5e433e83eaf12b56921ee4","7ec9605fb17547e783aacd86394ef67f","3e425ded24ec4d34a53584a432c95fd4","1a99107144594006b4753f7346133d2b","6f327d8206bd455b8f23cb9588fc2f23","41413b30437348b4bd2b9ea890b422ef","bf7a36849fe449d29b8e0deafc30c51c","f9fde8ca22f943a6a4e23fabd2e99ea5","ad827c99a4ea4885a21cfc5235a27260","25fdc55b847f428fb24ddfb4cf168b1b","716f3a4147f9466a9ca03b45247a5a81","90b308525d54467aa773cf48ae261b2e","d8aeb8cf04074a34953c5a088372132a","b9391a19be3d4b92983dc600bba66c68","1ba8d4eb7e0d411eaf64326bb92ad4e1","ca654f6378b0433aa06aafda336a4681","ce8dd627806f4f508aa5ae8556d7c0f5","cd8d3661997b4283b21fed557fed4166","29295c66dc3843b3a42616ac3e2a28d6","2c988b102e5e426babaed122ba76c1f1","0a4e350963db4b66ab8bd2d063525ddf","81ee08d3694d48218638d55bb76e8503","d8820089df70411eb788fe310bf87ec1","0e2e7b6db6194e02b025d714c5034a09","643ced3c83934a6085a1851d6bf33e2d","3098b54e46fd4234b67841a0ed4fa0ad","b523bbc9e6b949538f6ebd38021e3e86","f5a09781512d40a5a14d892308967c4b","7f49d92b6d6f44d1a011438ec65900b6","71d2c11ab70a46a093e120bb59e927d2","569a5ebda0924271832e0d58b7f2df4c","53fb6aebc0ee481bab05df82345f17f4","cbba1542bf904e73ab288be9a2ff86e4","5e1a3bbced104a0faab066365b43d9d9","0b491fd6ea6b410ab49eb54150097f10","b420159549304a8f9152434fd44947d2","173ebb345e4941068db42c8a0716f272","ed9abd7204964f45936d7d4cc5e47056","9113bb3ea145426fba787a32004d36ff","d7eaec8fc83343e5859ba59243d5f4b6","ffebc3c24bf347e58a4fce44731e448a","ea041fe809a54d059615b4dc69168749","c4cb6e187e7249d3a1083f65cbf42615","71ec60991836435ca35c2dea6ebd2c77","f6e22cf545fe4d67a374a10def5bf818"]},"id":"Dq3xI0Z80jZz","outputId":"65c9eb4a-d6ed-4ce2-eada-f54c1a883e30"},"source":["output = all_prediction(data,df_lexique_innovation,df_lexique_gestion,\"/content/drive/MyDrive/G5 Inter-Promo 2021/Ressources/test/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Phase 1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b941540bc9e24e60b2aabaaff775ec91","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7533.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ced1fe71eb146ac87868ea7edad89b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7533.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41413b30437348b4bd2b9ea890b422ef","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7533.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Iteration 0\n","Train f1: 0.9870578084555652\n","Now predicting labels for unlabeled data...\n","375 high-probability predictions added to training data.\n","4143 unlabeled instances remaining.\n","\n","Iteration 1\n","Train f1: 0.9898843930635838\n","Now predicting labels for unlabeled data...\n","96 high-probability predictions added to training data.\n","4047 unlabeled instances remaining.\n","\n","Iteration 2\n","Train f1: 0.989145183175034\n","Now predicting labels for unlabeled data...\n","39 high-probability predictions added to training data.\n","4008 unlabeled instances remaining.\n","\n","Iteration 3\n","Train f1: 0.9900727994705493\n","Now predicting labels for unlabeled data...\n","27 high-probability predictions added to training data.\n","3981 unlabeled instances remaining.\n","\n","Iteration 4\n","Train f1: 0.9896507115135834\n","Now predicting labels for unlabeled data...\n","33 high-probability predictions added to training data.\n","3948 unlabeled instances remaining.\n","\n","Iteration 5\n","Train f1: 0.9904275686024251\n","Now predicting labels for unlabeled data...\n","11 high-probability predictions added to training data.\n","3937 unlabeled instances remaining.\n","\n","Iteration 6\n","Train f1: 0.9891926255562619\n","Now predicting labels for unlabeled data...\n","7 high-probability predictions added to training data.\n","3930 unlabeled instances remaining.\n","\n","Iteration 7\n","Train f1: 0.9905243209096654\n","Now predicting labels for unlabeled data...\n","14 high-probability predictions added to training data.\n","3916 unlabeled instances remaining.\n","\n","Iteration 8\n","Train f1: 0.9893148962916405\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","3910 unlabeled instances remaining.\n","\n","Iteration 9\n","Train f1: 0.9887076537013803\n","Now predicting labels for unlabeled data...\n","13 high-probability predictions added to training data.\n","3897 unlabeled instances remaining.\n","\n","Iteration 10\n","Train f1: 0.9900249376558603\n","Now predicting labels for unlabeled data...\n","5 high-probability predictions added to training data.\n","3892 unlabeled instances remaining.\n","\n","Iteration 11\n","Train f1: 0.9900621118012422\n","Now predicting labels for unlabeled data...\n","7 high-probability predictions added to training data.\n","3885 unlabeled instances remaining.\n","\n","Iteration 12\n","Train f1: 0.9894606323620583\n","Now predicting labels for unlabeled data...\n","8 high-probability predictions added to training data.\n","3877 unlabeled instances remaining.\n","\n","Iteration 13\n","Train f1: 0.9907692307692308\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","3871 unlabeled instances remaining.\n","\n","Iteration 14\n","Train f1: 0.9895513214505224\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","3868 unlabeled instances remaining.\n","\n","Iteration 15\n","Train f1: 0.9883364027010436\n","Now predicting labels for unlabeled data...\n","9 high-probability predictions added to training data.\n","3859 unlabeled instances remaining.\n","\n","Iteration 16\n","Train f1: 0.9890377588306943\n","Now predicting labels for unlabeled data...\n","4 high-probability predictions added to training data.\n","3855 unlabeled instances remaining.\n","\n","Iteration 17\n","Train f1: 0.9884778653729533\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","3852 unlabeled instances remaining.\n","\n","Iteration 18\n","Train f1: 0.9891172914147521\n","Now predicting labels for unlabeled data...\n","9 high-probability predictions added to training data.\n","3843 unlabeled instances remaining.\n","\n","Iteration 19\n","Train f1: 0.9891566265060241\n","Now predicting labels for unlabeled data...\n","9 high-probability predictions added to training data.\n","3834 unlabeled instances remaining.\n","\n","Iteration 20\n","Train f1: 0.9904306220095694\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","3831 unlabeled instances remaining.\n","\n","Iteration 21\n","Train f1: 0.9898628503279666\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","3825 unlabeled instances remaining.\n","\n","Iteration 22\n","Train f1: 0.98989898989899\n","Now predicting labels for unlabeled data...\n","4 high-probability predictions added to training data.\n","3821 unlabeled instances remaining.\n","\n","Iteration 23\n","Train f1: 0.989922940130409\n","Now predicting labels for unlabeled data...\n","5 high-probability predictions added to training data.\n","3816 unlabeled instances remaining.\n","\n","Iteration 24\n","Train f1: 0.9893867924528302\n","Now predicting labels for unlabeled data...\n","4 high-probability predictions added to training data.\n","3812 unlabeled instances remaining.\n","\n","Iteration 25\n","Train f1: 0.9899823217442545\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","3809 unlabeled instances remaining.\n","\n","Iteration 26\n","Train f1: 0.9900058788947678\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","3803 unlabeled instances remaining.\n","\n","Iteration 27\n","Train f1: 0.9888300999412111\n","Now predicting labels for unlabeled data...\n","2 high-probability predictions added to training data.\n","3801 unlabeled instances remaining.\n","\n","Iteration 28\n","Train f1: 0.9905882352941177\n","Now predicting labels for unlabeled data...\n","8 high-probability predictions added to training data.\n","3793 unlabeled instances remaining.\n","\n","Iteration 29\n","Train f1: 0.9894982497082847\n","Now predicting labels for unlabeled data...\n","0 high-probability predictions added to training data.\n","3793 unlabeled instances remaining.\n","\n","Iteration 0\n","Train f1: 0.9994196169471851\n","Now predicting labels for unlabeled data...\n","3793 high-probability predictions added to training data.\n","0 unlabeled instances remaining.\n","\n","Iteration 1\n","Train f1: 0.9998286791159842\n","end of process.\n","Iteration 0\n","Train f1: 0.9974310669635211\n","end of process.\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9391a19be3d4b92983dc600bba66c68","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7533.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81ee08d3694d48218638d55bb76e8503","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7533.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71d2c11ab70a46a093e120bb59e927d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7533.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Iteration 0\n","Train f1: 0.9953271028037384\n","Now predicting labels for unlabeled data...\n","1187 high-probability predictions added to training data.\n","4485 unlabeled instances remaining.\n","\n","Iteration 1\n","Train f1: 0.9921011058451817\n","Now predicting labels for unlabeled data...\n","572 high-probability predictions added to training data.\n","3913 unlabeled instances remaining.\n","\n","Iteration 2\n","Train f1: 0.9922680412371134\n","Now predicting labels for unlabeled data...\n","247 high-probability predictions added to training data.\n","3666 unlabeled instances remaining.\n","\n","Iteration 3\n","Train f1: 0.9919999999999999\n","Now predicting labels for unlabeled data...\n","139 high-probability predictions added to training data.\n","3527 unlabeled instances remaining.\n","\n","Iteration 4\n","Train f1: 0.9926082365364307\n","Now predicting labels for unlabeled data...\n","84 high-probability predictions added to training data.\n","3443 unlabeled instances remaining.\n","\n","Iteration 5\n","Train f1: 0.9949341438703141\n","Now predicting labels for unlabeled data...\n","53 high-probability predictions added to training data.\n","3390 unlabeled instances remaining.\n","\n","Iteration 6\n","Train f1: 0.9930624380574826\n","Now predicting labels for unlabeled data...\n","29 high-probability predictions added to training data.\n","3361 unlabeled instances remaining.\n","\n","Iteration 7\n","Train f1: 0.9941291585127202\n","Now predicting labels for unlabeled data...\n","32 high-probability predictions added to training data.\n","3329 unlabeled instances remaining.\n","\n","Iteration 8\n","Train f1: 0.9922928709055876\n","Now predicting labels for unlabeled data...\n","17 high-probability predictions added to training data.\n","3312 unlabeled instances remaining.\n","\n","Iteration 9\n","Train f1: 0.99335232668566\n","Now predicting labels for unlabeled data...\n","12 high-probability predictions added to training data.\n","3300 unlabeled instances remaining.\n","\n","Iteration 10\n","Train f1: 0.9934272300469483\n","Now predicting labels for unlabeled data...\n","20 high-probability predictions added to training data.\n","3280 unlabeled instances remaining.\n","\n","Iteration 11\n","Train f1: 0.9934762348555453\n","Now predicting labels for unlabeled data...\n","27 high-probability predictions added to training data.\n","3253 unlabeled instances remaining.\n","\n","Iteration 12\n","Train f1: 0.9935245143385754\n","Now predicting labels for unlabeled data...\n","28 high-probability predictions added to training data.\n","3225 unlabeled instances remaining.\n","\n","Iteration 13\n","Train f1: 0.9926605504587156\n","Now predicting labels for unlabeled data...\n","18 high-probability predictions added to training data.\n","3207 unlabeled instances remaining.\n","\n","Iteration 14\n","Train f1: 0.993607305936073\n","Now predicting labels for unlabeled data...\n","25 high-probability predictions added to training data.\n","3182 unlabeled instances remaining.\n","\n","Iteration 15\n","Train f1: 0.9936421435059037\n","Now predicting labels for unlabeled data...\n","34 high-probability predictions added to training data.\n","3148 unlabeled instances remaining.\n","\n","Iteration 16\n","Train f1: 0.9918552036199095\n","Now predicting labels for unlabeled data...\n","27 high-probability predictions added to training data.\n","3121 unlabeled instances remaining.\n","\n","Iteration 17\n","Train f1: 0.9919999999999999\n","Now predicting labels for unlabeled data...\n","8 high-probability predictions added to training data.\n","3113 unlabeled instances remaining.\n","\n","Iteration 18\n","Train f1: 0.9938325991189427\n","Now predicting labels for unlabeled data...\n","8 high-probability predictions added to training data.\n","3105 unlabeled instances remaining.\n","\n","Iteration 19\n","Train f1: 0.9929824561403509\n","Now predicting labels for unlabeled data...\n","20 high-probability predictions added to training data.\n","3085 unlabeled instances remaining.\n","\n","Iteration 20\n","Train f1: 0.9930555555555556\n","Now predicting labels for unlabeled data...\n","12 high-probability predictions added to training data.\n","3073 unlabeled instances remaining.\n","\n","Iteration 21\n","Train f1: 0.9930915371329879\n","Now predicting labels for unlabeled data...\n","7 high-probability predictions added to training data.\n","3066 unlabeled instances remaining.\n","\n","Iteration 22\n","Train f1: 0.9922613929492691\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","3060 unlabeled instances remaining.\n","\n","Iteration 23\n","Train f1: 0.9914236706689538\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","3057 unlabeled instances remaining.\n","\n","Iteration 24\n","Train f1: 0.9923011120615911\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","3051 unlabeled instances remaining.\n","\n","Iteration 25\n","Train f1: 0.9914821124361158\n","Now predicting labels for unlabeled data...\n","2 high-probability predictions added to training data.\n","3049 unlabeled instances remaining.\n","\n","Iteration 26\n","Train f1: 0.9940627650551315\n","Now predicting labels for unlabeled data...\n","4 high-probability predictions added to training data.\n","3045 unlabeled instances remaining.\n","\n","Iteration 27\n","Train f1: 0.9923793395427604\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","3042 unlabeled instances remaining.\n","\n","Iteration 28\n","Train f1: 0.9932432432432432\n","Now predicting labels for unlabeled data...\n","0 high-probability predictions added to training data.\n","3042 unlabeled instances remaining.\n","\n","Iteration 0\n","Train f1: 0.9983193277310924\n","Now predicting labels for unlabeled data...\n","1387 high-probability predictions added to training data.\n","1655 unlabeled instances remaining.\n","\n","Iteration 1\n","Train f1: 0.9991349480968859\n","Now predicting labels for unlabeled data...\n","143 high-probability predictions added to training data.\n","1512 unlabeled instances remaining.\n","\n","Iteration 2\n","Train f1: 0.9991489361702128\n","Now predicting labels for unlabeled data...\n","51 high-probability predictions added to training data.\n","1461 unlabeled instances remaining.\n","\n","Iteration 3\n","Train f1: 0.9991546914623838\n","Now predicting labels for unlabeled data...\n","31 high-probability predictions added to training data.\n","1430 unlabeled instances remaining.\n","\n","Iteration 4\n","Train f1: 0.99915611814346\n","Now predicting labels for unlabeled data...\n","15 high-probability predictions added to training data.\n","1415 unlabeled instances remaining.\n","\n","Iteration 5\n","Train f1: 0.9991568296795953\n","Now predicting labels for unlabeled data...\n","9 high-probability predictions added to training data.\n","1406 unlabeled instances remaining.\n","\n","Iteration 6\n","Train f1: 0.9991568296795953\n","Now predicting labels for unlabeled data...\n","7 high-probability predictions added to training data.\n","1399 unlabeled instances remaining.\n","\n","Iteration 7\n","Train f1: 0.9991568296795953\n","Now predicting labels for unlabeled data...\n","6 high-probability predictions added to training data.\n","1393 unlabeled instances remaining.\n","\n","Iteration 8\n","Train f1: 0.9991575400168492\n","Now predicting labels for unlabeled data...\n","8 high-probability predictions added to training data.\n","1385 unlabeled instances remaining.\n","\n","Iteration 9\n","Train f1: 0.9991582491582491\n","Now predicting labels for unlabeled data...\n","5 high-probability predictions added to training data.\n","1380 unlabeled instances remaining.\n","\n","Iteration 10\n","Train f1: 0.9991589571068125\n","Now predicting labels for unlabeled data...\n","1 high-probability predictions added to training data.\n","1379 unlabeled instances remaining.\n","\n","Iteration 11\n","Train f1: 0.9991589571068125\n","Now predicting labels for unlabeled data...\n","0 high-probability predictions added to training data.\n","1379 unlabeled instances remaining.\n","\n","Iteration 0\n","Train f1: 1.0\n","Now predicting labels for unlabeled data...\n","1247 high-probability predictions added to training data.\n","132 unlabeled instances remaining.\n","\n","Iteration 1\n","Train f1: 1.0\n","Now predicting labels for unlabeled data...\n","104 high-probability predictions added to training data.\n","28 unlabeled instances remaining.\n","\n","Iteration 2\n","Train f1: 1.0\n","Now predicting labels for unlabeled data...\n","16 high-probability predictions added to training data.\n","12 unlabeled instances remaining.\n","\n","Iteration 3\n","Train f1: 1.0\n","Now predicting labels for unlabeled data...\n","3 high-probability predictions added to training data.\n","9 unlabeled instances remaining.\n","\n","Iteration 4\n","Train f1: 1.0\n","Now predicting labels for unlabeled data...\n","0 high-probability predictions added to training data.\n","9 unlabeled instances remaining.\n","\n","Phase 2\n","Phase 3\n","Phase 4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed9abd7204964f45936d7d4cc5e47056","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","We take 9 clusters.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sQ7FgbtlQjlw"},"source":["output.to_json(\"/content/drive/MyDrive/G5 Inter-Promo 2021/Données/Output/Global/Global_V2.json\",orient=\"records\")"],"execution_count":null,"outputs":[]}]}